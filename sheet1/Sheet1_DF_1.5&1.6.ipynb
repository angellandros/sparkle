{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as Funct\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import udf\n",
    "import csv\n",
    "\n",
    "sparkSession = SparkSession.builder.appName(\"myApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                 _c0|                 _c1|\n",
      "+--------------------+--------------------+\n",
      "|28d3f81251d94b097...|3929762,503574,58...|\n",
      "|d0c9aaa788153daea...|2080631,6343346,5...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exercise 1.5 (Loading the dataset into DataFrames)\n",
    "#users_libraries.txt\n",
    "df = sparkSession.read.csv(path=\"./mod_users_libraries.txt\", sep=';')\n",
    "df.show(2, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|        user_hash_id|paper_id|\n",
      "+--------------------+--------+\n",
      "|28d3f81251d94b097...| 3929762|\n",
      "|28d3f81251d94b097...|  503574|\n",
      "|28d3f81251d94b097...| 5819422|\n",
      "|28d3f81251d94b097...| 4238883|\n",
      "|28d3f81251d94b097...| 5788061|\n",
      "|28d3f81251d94b097...|  462949|\n",
      "|28d3f81251d94b097...|  635215|\n",
      "|28d3f81251d94b097...|  635216|\n",
      "|28d3f81251d94b097...| 4810441|\n",
      "|28d3f81251d94b097...| 3481823|\n",
      "|28d3f81251d94b097...| 4165233|\n",
      "|28d3f81251d94b097...| 3366480|\n",
      "|28d3f81251d94b097...| 5984302|\n",
      "|28d3f81251d94b097...| 4238942|\n",
      "|28d3f81251d94b097...| 5490453|\n",
      "|28d3f81251d94b097...| 4636156|\n",
      "|28d3f81251d94b097...| 5996865|\n",
      "|28d3f81251d94b097...| 4194836|\n",
      "|28d3f81251d94b097...| 5828780|\n",
      "|28d3f81251d94b097...| 4450195|\n",
      "|d0c9aaa788153daea...| 2080631|\n",
      "|d0c9aaa788153daea...| 6343346|\n",
      "|d0c9aaa788153daea...| 5184704|\n",
      "|d0c9aaa788153daea...| 7756088|\n",
      "|d0c9aaa788153daea...| 2653863|\n",
      "+--------------------+--------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exercise 1.5 (Loading the dataset into DataFrames)\n",
    "#users_libraries.txt\n",
    "userLibRDD = sparkSession.sparkContext.textFile(\"./mod_users_libraries.txt\")\\\n",
    "                .map(lambda x: (x.split(';')[0], x.split(';')[1]))\\\n",
    "                .map(lambda x: (x[0], x[1].split(',')))\\\n",
    "                .flatMapValues(lambda x: x)\n",
    "#userLibRDD.take(100)\n",
    "schemaString = \"user_hash_id paper_id\"\n",
    "fields = [StructField(field_name, StringType(), True) for field_name in schemaString.split()]\n",
    "schema = StructType(fields)\n",
    "userLibDF = sparkSession.createDataFrame(userLibRDD, schema)\n",
    "\n",
    "userLibDF.show(25, truncate=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------------------+----------+------+---------+-----+------+------+----+-----+-------------------+-------+--------------------+--------------------+\n",
      "|paper_id|   type|             journal|book_title|series|publisher|pages|volume|number|year|month|          postedate|address|               title|            abstract|\n",
      "+--------+-------+--------------------+----------+------+---------+-----+------+------+----+-----+-------------------+-------+--------------------+--------------------+\n",
      "|   80546|article|biology and philo...|      null|  null|     null|   17|    19|     2|2004|  mar|2005-01-26 21:35:21|   null|the arbitrariness...|the genetic code ...|\n",
      "| 5842862|article|      molecular cell|      null|  null| elsevier|    2|    35|     6|2009|  sep|2009-09-30 17:11:23|   null|how to choose a g...|choosing good pro...|\n",
      "+--------+-------+--------------------+----------+------+---------+-----+------+------+----+-----+-------------------+-------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exercise 1.5 (Loading the dataset into DataFrames)\n",
    "#papers.csv\n",
    "columns = ['paper_id', 'type', 'journal', 'book_title', 'series', 'publisher', 'pages', 'volume', 'number', 'year', 'month', 'postedate', 'address', 'title', 'abstract']\n",
    "papersDF = sparkSession.read.load(\"./papers.csv\", format=\"csv\", sep=\",\", inferSchema=\"true\", quote='\"', header=\"false\").toDF(*columns)\n",
    "papersDF.show(2, truncate=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|stop_word|\n",
      "+---------+\n",
      "|        a|\n",
      "|     able|\n",
      "|    about|\n",
      "|    above|\n",
      "|according|\n",
      "+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exercise 1.5 (Loading the dataset into DataFrames)\n",
    "#stopwords_en.txt\n",
    "stopWordsDF = sparkSession.read.load(\"./stopwords_en.txt\", format=\"text\", sep=\" \", inferSchema=\"true\", header=\"false\").toDF('stop_word')\n",
    "stopWordsDF.show(5, truncate=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exercise 1.6 (Tasks on top of DataFrames)\n",
    "#Exercise 1.4 a) Using DataFrames (Basic Analysis for Recommender Systems)\n",
    "#Number of distinct users\n",
    "userLibDF.select(\"user_hash_id\").distinct().count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172079"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exercise 1.6 (Tasks on top of DataFrames)\n",
    "#Exercise 1.4 a) Using DataFrames (Basic Analysis for Recommender Systems)\n",
    "#Number of distinct items\n",
    "papersDF.select(\"paper_id\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30149"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exercise 1.6 (Tasks on top of DataFrames)\n",
    "#Exercise 1.4 a) Using DataFrames (Basic Analysis for Recommender Systems)\n",
    "#Number of ratings\n",
    "userLibDF.select(\"paper_id\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|min(count)|\n",
      "+----------+\n",
      "|         1|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exercise 1.6 (Tasks on top of DataFrames)\n",
    "#Exercise 1.4 b) Using DataFrames (Basic Analysis for Recommender Systems)\n",
    "#Min number of ratings a user has given\n",
    "userLibDF.select(\"user_hash_id\").groupBy(\"user_hash_id\").count().agg(Funct.min(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|max(count)|\n",
      "+----------+\n",
      "|       950|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exercise 1.6 (Tasks on top of DataFrames)\n",
    "#Exercise 1.4 c) Using DataFrames (Basic Analysis for Recommender Systems)\n",
    "#Max number of ratings a user has given\n",
    "userLibDF.select(\"user_hash_id\").groupBy(\"user_hash_id\").count().agg(Funct.max(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|avg(count)|\n",
      "+----------+\n",
      "|    30.149|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exercise 1.6 (Tasks on top of DataFrames)\n",
    "#Exercise 1.4 d) Using DataFrames (Basic Analysis for Recommender Systems)\n",
    "#Average number of ratings of users\n",
    "userLibDF.select(\"user_hash_id\").groupBy(\"user_hash_id\").count().agg(Funct.mean(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|stddev_samp(count)|\n",
      "+------------------+\n",
      "|  71.4915368336619|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exercise 1.6 (Tasks on top of DataFrames)\n",
    "#Exercise 1.4 e) Using DataFrames (Basic Analysis for Recommender Systems)\n",
    "#Standard deviation for ratings of users\n",
    "userLibDF.select(\"user_hash_id\").groupBy(\"user_hash_id\").count().agg(Funct.stddev(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|min(count)|\n",
      "+----------+\n",
      "|         1|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exercise 1.6 (Tasks on top of DataFrames)\n",
    "#Exercise 1.4 f) Using DataFrames (Basic Analysis for Recommender Systems)\n",
    "#Min number of ratings an item has received\n",
    "userLibDF.select(\"paper_id\").groupBy(\"paper_id\").count().agg(Funct.min(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|max(count)|\n",
      "+----------+\n",
      "|        30|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exercise 1.6 (Tasks on top of DataFrames)\n",
    "#Exercise 1.4 g) Using DataFrames (Basic Analysis for Recommender Systems)\n",
    "#Max number of ratings an item has received\n",
    "userLibDF.select(\"paper_id\").groupBy(\"paper_id\").count().agg(Funct.max(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|        avg(count)|\n",
      "+------------------+\n",
      "|1.1188673643583462|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exercise 1.6 (Tasks on top of DataFrames)\n",
    "#Exercise 1.4 h) Using DataFrames (Basic Analysis for Recommender Systems)\n",
    "#Average number of ratings of items\n",
    "userLibDF.select(\"paper_id\").groupBy(\"paper_id\").count().agg(Funct.mean(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "| stddev_samp(count)|\n",
      "+-------------------+\n",
      "|0.47627972494626164|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exercise 1.6 (Tasks on top of DataFrames)\n",
    "#Exercise 1.4 i) Using DataFrames (Basic Analysis for Recommender Systems)\n",
    "#Average number of ratings of items\n",
    "userLibDF.select(\"paper_id\").groupBy(\"paper_id\").count().agg(Funct.stddev(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|        user_hash_id|   word|\n",
      "+--------------------+-------+\n",
      "|a6f5b862e26386cec...|   this|\n",
      "|a6f5b862e26386cec...|  paper|\n",
      "|a6f5b862e26386cec...|     is|\n",
      "|a6f5b862e26386cec...|    the|\n",
      "|a6f5b862e26386cec...|  fifth|\n",
      "|a6f5b862e26386cec...|     in|\n",
      "|a6f5b862e26386cec...|      a|\n",
      "|a6f5b862e26386cec...| series|\n",
      "|a6f5b862e26386cec...|     of|\n",
      "|a6f5b862e26386cec...|studies|\n",
      "+--------------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exercise 1.6\n",
    "#Exercise 1.3 Using Dataframes (Joining collections)\n",
    "#Joining the userLib dataframe with the papersDf dataframe over paper_id\n",
    "#Dropping any row that has null value in the abstract column\n",
    "joinedDF = userLibDF.join(papersDF, userLibDF.paper_id == papersDF.paper_id, \"inner\")\\\n",
    "                        .select(userLibDF.user_hash_id,\\\n",
    "                                Funct.explode(Funct.split(papersDF.abstract,\" \"))\\\n",
    "                                .alias(\"word\"))\\\n",
    "                        .na.drop(\"any\")\n",
    "\n",
    "joinedDF.show(10, truncate=True)\n",
    "#joinedDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|        user_hash_id|            word|\n",
      "+--------------------+----------------+\n",
      "|a6f5b862e26386cec...|           paper|\n",
      "|a6f5b862e26386cec...|          series|\n",
      "|a6f5b862e26386cec...|         studies|\n",
      "|a6f5b862e26386cec...|       emanating|\n",
      "|a6f5b862e26386cec...|            {uk}|\n",
      "|a6f5b862e26386cec...|           joint|\n",
      "|a6f5b862e26386cec...|     information|\n",
      "|a6f5b862e26386cec...|         systems|\n",
      "|a6f5b862e26386cec...|       committee|\n",
      "|a6f5b862e26386cec...| ({jisc})-funded|\n",
      "|a6f5b862e26386cec...|         {romeo}|\n",
      "|a6f5b862e26386cec...|         project|\n",
      "|a6f5b862e26386cec...|         (rights|\n",
      "|a6f5b862e26386cec...|        metadata|\n",
      "|a6f5b862e26386cec...|open-archiving).|\n",
      "|a6f5b862e26386cec...|           paper|\n",
      "|a6f5b862e26386cec...|         reports|\n",
      "|a6f5b862e26386cec...|         results|\n",
      "|a6f5b862e26386cec...|         surveys|\n",
      "|a6f5b862e26386cec...|           {oai}|\n",
      "+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exercise 1.6\n",
    "#Exercise 1.3 Using Dataframes (Joining collections)\n",
    "#Subtracting the stop words from the user and abstract words dataframe\n",
    "withoutStpWrdDF = joinedDF.join(stopWordsDF, joinedDF.word==stopWordsDF.stop_word, how=\"left_anti\")\n",
    "#withoutStpWrdDF.count()\n",
    "withoutStpWrdDF.show(20, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+----------+\n",
      "|        user_hash_id|     word|word_count|\n",
      "+--------------------+---------+----------+\n",
      "|003840e52f6a43bc5...| striking|         1|\n",
      "|003840e52f6a43bc5...|politics.|         1|\n",
      "|003840e52f6a43bc5...|   brings|         1|\n",
      "|003840e52f6a43bc5...| policies|         1|\n",
      "|003840e52f6a43bc5...|    these|         2|\n",
      "|003840e52f6a43bc5...|    life.|         1|\n",
      "|003840e52f6a43bc5...|  meaning|         1|\n",
      "|003840e52f6a43bc5...|disasters|         1|\n",
      "|003840e52f6a43bc5...|   framed|         1|\n",
      "|003840e52f6a43bc5...| american|         2|\n",
      "+--------------------+---------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exercise 1.6\n",
    "#Exercise 1.3 Using Dataframes (Joining collections)\n",
    "#Grouping the joinedDf dataframe over 'user_hash_id' and 'word' columns\n",
    "#Sorting in ascending order the result w.r.t the 'user_hash_id' column\n",
    "groupedDF = joinedDF.groupBy(\"user_hash_id\", \"word\")\\\n",
    "                    .agg(Funct.count(\"word\").alias(\"word_count\"))\\\n",
    "                    .sort(Funct.asc(\"user_hash_id\"))\n",
    "\n",
    "groupedDF.show(10, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|        user_hash_id|     word|ranking|\n",
      "+--------------------+---------+-------+\n",
      "|003840e52f6a43bc5...|      the|      1|\n",
      "|003840e52f6a43bc5...|       of|      2|\n",
      "|003840e52f6a43bc5...|      and|      3|\n",
      "|003840e52f6a43bc5...|       in|      4|\n",
      "|003840e52f6a43bc5...|       to|      5|\n",
      "|003840e52f6a43bc5...|        a|      6|\n",
      "|003840e52f6a43bc5...|   social|      7|\n",
      "|003840e52f6a43bc5...|     that|      8|\n",
      "|003840e52f6a43bc5...|      war|      9|\n",
      "|003840e52f6a43bc5...|       by|      9|\n",
      "|003840e52f6a43bc5...|     this|      9|\n",
      "|00be9ee3318c2cf69...|       of|      1|\n",
      "|00be9ee3318c2cf69...|      the|      2|\n",
      "|00be9ee3318c2cf69...|      and|      3|\n",
      "|00be9ee3318c2cf69...|       in|      4|\n",
      "|00be9ee3318c2cf69...|  {rhios}|      5|\n",
      "|00be9ee3318c2cf69...|     that|      6|\n",
      "|00be9ee3318c2cf69...|       to|      6|\n",
      "|00be9ee3318c2cf69...|hospitals|      6|\n",
      "|00be9ee3318c2cf69...|    {hie}|      6|\n",
      "|00be9ee3318c2cf69...|       is|      6|\n",
      "|00be9ee3318c2cf69...|   health|      6|\n",
      "|00be9ee3318c2cf69...|      for|      6|\n",
      "|00be9ee3318c2cf69...|        a|      6|\n",
      "|013ceaa3340e4ee4f...|      the|      1|\n",
      "|013ceaa3340e4ee4f...|      and|      2|\n",
      "|013ceaa3340e4ee4f...|       of|      3|\n",
      "|013ceaa3340e4ee4f...|       to|      4|\n",
      "|013ceaa3340e4ee4f...|       in|      5|\n",
      "|013ceaa3340e4ee4f...|      for|      6|\n",
      "+--------------------+---------+-------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exercise 1.6\n",
    "#Exercise 1.3 Using Dataframes (Joining collections)\n",
    "#Creating a window and using 'rank' function over the window to give a rank to the words per user and according \n",
    "#to the word count\n",
    "window = Window.partitionBy(\"user_hash_id\").orderBy(Funct.desc(\"word_count\"))\n",
    "rankedResultDF = groupedDF.withColumn(\"ranking\", Funct.rank().over(window))\n",
    "filteredRankedResDF = rankedResultDF.filter(rankedResultDF.ranking < 10).select(\"user_hash_id\", \"word\", \"ranking\")\n",
    "filteredRankedResDF.show(30, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
